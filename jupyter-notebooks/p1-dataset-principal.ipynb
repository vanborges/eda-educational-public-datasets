{
 "cells": [
  {
   "source": [
    "# Análise dos microdados ENADE (parte 1)\n",
    "## Criando o dataset principal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Carrengando os datasets disponíveis no INEP (2016 a 2019)\n",
    "- https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/BI-GOV/enade/csv/'\n",
    "\n",
    "file_enade19 = path+'microdados_enade_2019.txt'\n",
    "df_19 = pd.read_csv(file_enade19, sep=';', encoding='latin1')\n",
    "file_enade18 = path+'microdados_enade_2018.txt'\n",
    "df_18 = pd.read_csv(file_enade18, sep=';', encoding='latin1')\n",
    "file_enade17 = path+'microdados_enade_2017.txt'\n",
    "df_17 = pd.read_csv(file_enade17, sep=';', encoding='latin1')\n",
    "file_enade16 = path+'microdados_enade_2016.txt'\n",
    "df_16 = pd.read_csv(file_enade16, sep=';', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a coluna de ano\n",
    "df_19['ENADE_ANO'] = 2019\n",
    "df_18['ENADE_ANO'] = 2018\n",
    "df_17['ENADE_ANO'] = 2017\n",
    "df_16['ENADE_ANO'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suited-percentage",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(433930, 138)\n(548127, 138)\n(537436, 151)\n(216044, 142)\n"
     ]
    }
   ],
   "source": [
    "#Verificando a quantidade de linhas e colunas nos datasets\n",
    "print(df_19.shape)\n",
    "print(df_18.shape)\n",
    "print(df_17.shape)\n",
    "print(df_16.shape)"
   ]
  },
  {
   "source": [
    "## Resolvendo pequenas diferenças entre arquivos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16-17:  Index(['AMOSTRA', 'ANO_FIM_2G', 'ID_STATUS', 'IN_GRAD', 'IN_MATUT',\n       'IN_NOTURNO', 'IN_VESPER', 'TP_SEMESTRE'],\n      dtype='object')\n17-16:  Index(['ANO_FIM_EM', 'CO_TURNO_GRADUACAO', 'QE_I69', 'QE_I70', 'QE_I71',\n       'QE_I72', 'QE_I73', 'QE_I74', 'QE_I75', 'QE_I76', 'QE_I77', 'QE_I78',\n       'QE_I79', 'QE_I80', 'QE_I81', 'TP_INSCRICAO', 'TP_INSCRICAO_ADM'],\n      dtype='object')\n16-18:  Index(['AMOSTRA', 'ANO_FIM_2G', 'ID_STATUS', 'IN_GRAD', 'IN_MATUT',\n       'IN_NOTURNO', 'IN_VESPER', 'TP_SEMESTRE'],\n      dtype='object')\n18-16:  Index(['ANO_FIM_EM', 'CO_TURNO_GRADUACAO', 'TP_INSCRICAO', 'TP_INSCRICAO_ADM'], dtype='object')\n16-19:  Index(['AMOSTRA', 'ANO_FIM_2G', 'ID_STATUS', 'IN_GRAD', 'IN_MATUT',\n       'IN_NOTURNO', 'IN_VESPER', 'TP_SEMESTRE'],\n      dtype='object')\n19-16:  Index(['ANO_FIM_EM', 'CO_TURNO_GRADUACAO', 'TP_INSCRICAO', 'TP_INSCRICAO_ADM'], dtype='object')\n17-18:  Index(['QE_I69', 'QE_I70', 'QE_I71', 'QE_I72', 'QE_I73', 'QE_I74', 'QE_I75',\n       'QE_I76', 'QE_I77', 'QE_I78', 'QE_I79', 'QE_I80', 'QE_I81'],\n      dtype='object')\n17-19:  Index(['QE_I69', 'QE_I70', 'QE_I71', 'QE_I72', 'QE_I73', 'QE_I74', 'QE_I75',\n       'QE_I76', 'QE_I77', 'QE_I78', 'QE_I79', 'QE_I80', 'QE_I81'],\n      dtype='object')\n18-19:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"16-17: \", df_16.columns.difference(df_17.columns))\n",
    "print(\"17-16: \", df_17.columns.difference(df_16.columns))\n",
    "print(\"16-18: \", df_16.columns.difference(df_18.columns))\n",
    "print(\"18-16: \", df_18.columns.difference(df_16.columns))\n",
    "print(\"16-19: \", df_16.columns.difference(df_19.columns))\n",
    "print(\"19-16: \", df_19.columns.difference(df_16.columns))\n",
    "print(\"17-18: \", df_17.columns.difference(df_18.columns))\n",
    "print(\"17-19: \", df_17.columns.difference(df_19.columns))\n",
    "print(\"18-19: \", df_18.columns.difference(df_19.columns))\n"
   ]
  },
  {
   "source": [
    "- As questões QE_I69 a QE_I81 são itens exclusivos para os Estudantes das Licenciaturas e só aparecem em 2017, serão removidos\n",
    "\n",
    "- Essas colunas que só estão em 2016 serão removidas: 'AMOSTRA', 'ID_STATUS', 'TP_SEMESTRE', 'IN_GRAD'\n",
    "\n",
    "- Renomeando ANO_FIM_2G para ANO_EM\n",
    "\n",
    "- Alterar 'IN_MATUT','IN_NOTURNO', 'IN_VESPER' para CO_TURNO_GRADUACAO\n",
    "\n",
    "- Colunas 'TP_INSCRICAO_ADM' e 'TP_INSCRICAO' não estão em 2016\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#As questões QE_I69 a QE_I81 são itens exclusivos para os Estudantes das Licenciaturas e só aparecem em 2017, serão removidos\n",
    "df_17.drop(columns=['QE_I69', 'QE_I70', 'QE_I71', 'QE_I72', 'QE_I73', 'QE_I74', 'QE_I75',\n",
    "       'QE_I76', 'QE_I77', 'QE_I78', 'QE_I79', 'QE_I80', 'QE_I81'], inplace=True, errors='ignore')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo as colunas a mais do dataset de 2016\n",
    "df_16.drop(columns=['AMOSTRA', 'ID_STATUS', 'TP_SEMESTRE','IN_GRAD'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando ANO_FIM_2G para ANO_FIM_EM\n",
    "# Renomeando IN_GRAD para ANO_IN_GRAD\n",
    "#df_16.rename(columns={'ANO_FIM_2G':'ANO_FIM_EM', 'IN_GRAD':'ANO_IN_GRAD'}, inplace=True)\n",
    "df_16.rename(columns={'ANO_FIM_2G':'ANO_FIM_EM'}, inplace=True)"
   ]
  },
  {
   "source": [
    "# Alterar 'IN_MATUT','IN_NOTURNO', 'IN_VESPER' para CO_TURNO_GRADUACAO e removendo essas colunas\n",
    "def convert(ma,ve,no):\n",
    "    if (ma+ve+no)>1:\n",
    "        return 3\n",
    "    if ma==1:\n",
    "        return 1\n",
    "    if ve==1:\n",
    "        return 2\n",
    "    if no==1:\n",
    "        return 4\n",
    "    return null\n",
    "\n",
    "df_16['CO_TURNO_GRADUACAO'] = df_16[['IN_MATUT', 'IN_VESPER', 'IN_NOTURNO']].apply(lambda x:convert(x['IN_MATUT'], x['IN_VESPER'], x['IN_NOTURNO']), axis=1)\n",
    "\n",
    "df_16.drop(columns=['IN_MATUT', 'IN_NOTURNO', 'IN_VESPER'], inplace=True, errors='ignore')\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserindo colunas faltantes no dataset de 2016\n",
    "\n",
    "df_16.insert(df_19.columns.get_loc('TP_INSCRICAO'), 'TP_INSCRICAO', np.nan,  allow_duplicates=False)\n",
    "\n",
    "df_16.insert(df_19.columns.get_loc('TP_INSCRICAO_ADM'), 'TP_INSCRICAO_ADM', np.nan,  allow_duplicates=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16-17:  Index([], dtype='object')\n17-16:  Index([], dtype='object')\n16-18:  Index([], dtype='object')\n18-16:  Index([], dtype='object')\n16-19:  Index([], dtype='object')\n19-16:  Index([], dtype='object')\n17-18:  Index([], dtype='object')\n17-19:  Index([], dtype='object')\n18-19:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verificando se removeu todas as diferenças\n",
    "print(\"16-17: \", df_16.columns.difference(df_17.columns))\n",
    "print(\"17-16: \", df_17.columns.difference(df_16.columns))\n",
    "print(\"16-18: \", df_16.columns.difference(df_18.columns))\n",
    "print(\"18-16: \", df_18.columns.difference(df_16.columns))\n",
    "print(\"16-19: \", df_16.columns.difference(df_19.columns))\n",
    "print(\"19-16: \", df_19.columns.difference(df_16.columns))\n",
    "print(\"17-18: \", df_17.columns.difference(df_18.columns))\n",
    "print(\"17-19: \", df_17.columns.difference(df_19.columns))\n",
    "print(\"18-19: \", df_18.columns.difference(df_19.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16  (216044, 138)\n17  (537436, 138)\n18  (548127, 138)\n19  (433930, 138)\n"
     ]
    }
   ],
   "source": [
    "# Todos os dataframes tem a mesma quantidade de colunas\n",
    "print(\"16 \", df_16.shape)\n",
    "print(\"17 \", df_17.shape)\n",
    "print(\"18 \", df_18.shape)\n",
    "print(\"19 \", df_19.shape)"
   ]
  },
  {
   "source": [
    "## Gerando o arquivo csv com todos os datasets (2016 a 2019)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_16, df_17, df_18, df_19]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo linhas que possuem muitos valores null\n",
    "df.dropna(how='any', thresh=20,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o arquivo csv final\n",
    "df.to_csv(path+'enade16_19.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "04dd1ea88422301727d19c42d51b9d5e41ad8601a3578a3c62991af58a4da346"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}