{
 "cells": [
  {
   "source": [
    "# Análise dos microdados ENADE (parte 1)\n",
    "## Criando o dataset principal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Carrengando os datasets disponíveis no INEP (2016 a 2019)\n",
    "- https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'fileenade19' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-98df76bfe7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_enade19\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'microdados_enade_2019.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_19\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileenade19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfile_enade18\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'microdados_enade_2018.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_18\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_enade18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fileenade19' is not defined"
     ]
    }
   ],
   "source": [
    "path='C:/BI-GOV/eda-git/eda-educational-public-datasets/datasets/enade/'\n",
    "\n",
    "file_enade19 = path+'microdados_enade_2019.txt'\n",
    "df_19 = pd.read_csv(file_enade19, sep=';', encoding='latin1', low_memory=False)\n",
    "file_enade18 = path+'microdados_enade_2018.txt'\n",
    "df_18 = pd.read_csv(file_enade18, sep=';', encoding='latin1', low_memory=False)\n",
    "file_enade17 = path+'microdados_enade_2017.txt'\n",
    "df_17 = pd.read_csv(file_enade17, sep=';', encoding='latin1', low_memory=False)\n",
    "file_enade16 = path+'microdados_enade_2016.txt'\n",
    "df_16 = pd.read_csv(file_enade16, sep=';', encoding='latin1',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a coluna de ano\n",
    "df_19['ENADE_ANO'] = 2019\n",
    "df_18['ENADE_ANO'] = 2018\n",
    "df_17['ENADE_ANO'] = 2017\n",
    "df_16['ENADE_ANO'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a quantidade de linhas e colunas nos datasets\n",
    "print(df_19.shape)\n",
    "print(df_18.shape)\n",
    "print(df_17.shape)\n",
    "print(df_16.shape)"
   ]
  },
  {
   "source": [
    "## Resolvendo pequenas diferenças entre arquivos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"16-17: \", df_16.columns.difference(df_17.columns))\n",
    "print(\"17-16: \", df_17.columns.difference(df_16.columns))\n",
    "print(\"16-18: \", df_16.columns.difference(df_18.columns))\n",
    "print(\"18-16: \", df_18.columns.difference(df_16.columns))\n",
    "print(\"16-19: \", df_16.columns.difference(df_19.columns))\n",
    "print(\"19-16: \", df_19.columns.difference(df_16.columns))\n",
    "print(\"17-18: \", df_17.columns.difference(df_18.columns))\n",
    "print(\"17-19: \", df_17.columns.difference(df_19.columns))\n",
    "print(\"18-19: \", df_18.columns.difference(df_19.columns))\n"
   ]
  },
  {
   "source": [
    "- As questões QE_I69 a QE_I81 são itens exclusivos para os Estudantes das Licenciaturas e só aparecem em 2017, serão removidos\n",
    "\n",
    "- Essas colunas que só estão em 2016 serão removidas: 'AMOSTRA', 'ID_STATUS', 'TP_SEMESTRE', 'IN_GRAD'\n",
    "\n",
    "- Renomeando ANO_FIM_2G para ANO_EM\n",
    "\n",
    "- Alterar 'IN_MATUT','IN_NOTURNO', 'IN_VESPER' para CO_TURNO_GRADUACAO\n",
    "\n",
    "- Colunas 'TP_INSCRICAO_ADM' e 'TP_INSCRICAO' não estão em 2016\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#As questões QE_I69 a QE_I81 são itens exclusivos para os Estudantes das Licenciaturas e só aparecem em 2017, serão removidos\n",
    "df_17.drop(columns=['QE_I69', 'QE_I70', 'QE_I71', 'QE_I72', 'QE_I73', 'QE_I74', 'QE_I75',\n",
    "       'QE_I76', 'QE_I77', 'QE_I78', 'QE_I79', 'QE_I80', 'QE_I81'], inplace=True, errors='ignore')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo as colunas a mais do dataset de 2016\n",
    "df_16.drop(columns=['AMOSTRA', 'ID_STATUS', 'TP_SEMESTRE','IN_GRAD'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando ANO_FIM_2G para ANO_FIM_EM\n",
    "# Renomeando IN_GRAD para ANO_IN_GRAD\n",
    "#df_16.rename(columns={'ANO_FIM_2G':'ANO_FIM_EM', 'IN_GRAD':'ANO_IN_GRAD'}, inplace=True)\n",
    "df_16.rename(columns={'ANO_FIM_2G':'ANO_FIM_EM'}, inplace=True)"
   ]
  },
  {
   "source": [
    "# Alterar 'IN_MATUT','IN_NOTURNO', 'IN_VESPER' para CO_TURNO_GRADUACAO e removendo essas colunas\n",
    "def convert(ma,ve,no):\n",
    "    if (ma+ve+no)>1:\n",
    "        return 3\n",
    "    if ma==1:\n",
    "        return 1\n",
    "    if ve==1:\n",
    "        return 2\n",
    "    if no==1:\n",
    "        return 4\n",
    "    return null\n",
    "\n",
    "df_16['CO_TURNO_GRADUACAO'] = df_16[['IN_MATUT', 'IN_VESPER', 'IN_NOTURNO']].apply(lambda x:convert(x['IN_MATUT'], x['IN_VESPER'], x['IN_NOTURNO']), axis=1)\n",
    "\n",
    "df_16.drop(columns=['IN_MATUT', 'IN_NOTURNO', 'IN_VESPER'], inplace=True, errors='ignore')\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserindo colunas faltantes no dataset de 2016\n",
    "\n",
    "df_16.insert(df_19.columns.get_loc('TP_INSCRICAO'), 'TP_INSCRICAO', np.nan,  allow_duplicates=False)\n",
    "\n",
    "df_16.insert(df_19.columns.get_loc('TP_INSCRICAO_ADM'), 'TP_INSCRICAO_ADM', np.nan,  allow_duplicates=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se removeu todas as diferenças\n",
    "print(\"16-17: \", df_16.columns.difference(df_17.columns))\n",
    "print(\"17-16: \", df_17.columns.difference(df_16.columns))\n",
    "print(\"16-18: \", df_16.columns.difference(df_18.columns))\n",
    "print(\"18-16: \", df_18.columns.difference(df_16.columns))\n",
    "print(\"16-19: \", df_16.columns.difference(df_19.columns))\n",
    "print(\"19-16: \", df_19.columns.difference(df_16.columns))\n",
    "print(\"17-18: \", df_17.columns.difference(df_18.columns))\n",
    "print(\"17-19: \", df_17.columns.difference(df_19.columns))\n",
    "print(\"18-19: \", df_18.columns.difference(df_19.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os dataframes tem a mesma quantidade de colunas\n",
    "print(\"16 \", df_16.shape)\n",
    "print(\"17 \", df_17.shape)\n",
    "print(\"18 \", df_18.shape)\n",
    "print(\"19 \", df_19.shape)"
   ]
  },
  {
   "source": [
    "## Gerando o arquivo csv com todos os datasets (2016 a 2019)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_16, df_17, df_18, df_19]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo linhas que possuem muitos valores null\n",
    "df.dropna(how='any', thresh=20,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o arquivo csv final\n",
    "df.to_csv(path+'enade16_19.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "04dd1ea88422301727d19c42d51b9d5e41ad8601a3578a3c62991af58a4da346"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}